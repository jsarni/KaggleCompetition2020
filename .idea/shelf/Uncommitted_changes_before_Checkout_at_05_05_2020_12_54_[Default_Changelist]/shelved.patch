Index: DatasetReader/DatasetReader_merzouk.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import pathlib\r\n\r\nimport os\r\nimport pandas as pd\r\nimport numpy as np\r\nimport random\r\nimport re\r\nfrom PIL import Image\r\nimport glob\r\nimport pickle\r\nfrom vars_merzouk import *\r\n\r\n\r\ndef split_dataset():\r\n    print('> Started splitting dataset to train and test batches')\r\n    train_batches_list = [i for i in range(NB_BATCHES)]\r\n    random.shuffle(train_batches_list)\r\n    nb_test_batches = int(0.2 * NB_BATCHES)\r\n    test_batch_list = []\r\n    for i in range(nb_test_batches):\r\n        selected_batch = random.choice(train_batches_list)\r\n        test_batch_list.append(selected_batch)\r\n        train_batches_list.remove(selected_batch)\r\n\r\n    return train_batches_list, test_batch_list\r\n\r\n\r\ndef read_image(image_id):\r\n    image_path_root = '{}{}.*'.format(IMAGES_DIR, image_id)\r\n    image_path = glob.glob(image_path_root)[0]\r\n\r\n    image = Image.open(image_path)\r\n    image = image.resize((IMAGE_HEIGHT, IMAGE_LENGTH))\r\n    image_np = np.array(image)\r\n    return image_np\r\n\r\n\r\ndef read_batch_images(batch_number):\r\n    print('> Started loading batch images')\r\n    batch_path = '{}{}{}'.format(BATCHES_DIR, BATCHES_FILES_ROOT, batch_number)\r\n    batch = pd.read_csv(batch_path)\r\n\r\n    images_ids = batch['image_id'].to_list()\r\n\r\n    images_list = []\r\n\r\n    for image in images_ids:\r\n        images_list.append(read_image(image))\r\n\r\n    return np.array(images_list)\r\n\r\n\r\ndef int_list_from_str(string):\r\n    clean_string = re.sub(r'[\\[\\] ]', \"\", string)\r\n    return [int(i) for i in clean_string.split(',')]\r\n\r\n\r\ndef read_batch_labels(batch_number):\r\n    print('> Started loading batch labels')\r\n    batch_path = '{}{}{}'.format(BATCHES_DIR, BATCHES_FILES_ROOT, batch_number)\r\n    batch = pd.read_csv(batch_path)\r\n\r\n    labels_str = batch['category_id'].to_list()\r\n\r\n    labels = np.array([[int(label_str)] for label_str in labels_str])\r\n    return labels\r\n\r\n\r\ndef load_unsplitted_batch(batch_number):\r\n    batch_images = read_batch_images(batch_number)\r\n    batch_labels = read_batch_labels(batch_number)\r\n\r\n    return batch_images, batch_labels\r\n\r\n\r\ndef load_splitted_batch(batch_number):\r\n    batch_images, batch_labels = load_unsplitted_batch(batch_number)\r\n    return split_images_to_train_and_test(batch_images, batch_labels)\r\n\r\ndef read_image_to_pickle(image_id):\r\n    image_path_root = '{}{}.*'.format(IMAGES_DIR, image_id)\r\n    image_path = glob.glob(image_path_root)[0]\r\n\r\n    pathlib.Path(PICKELED_IMAGES_DIR).mkdir(parents=True, exist_ok=True)\r\n    pathlib.Path(PICKELED_IMAGES_DIR + '16\\\\').mkdir(parents=True, exist_ok=True)\r\n    pathlib.Path(PICKELED_IMAGES_DIR + '32\\\\').mkdir(parents=True, exist_ok=True)\r\n    pathlib.Path(PICKELED_IMAGES_DIR + '64\\\\').mkdir(parents=True, exist_ok=True)\r\n    pathlib.Path(PICKELED_IMAGES_DIR + '128\\\\').mkdir(parents=True, exist_ok=True)\r\n    pathlib.Path(PICKELED_IMAGES_DIR + '256\\\\').mkdir(parents=True, exist_ok=True)\r\n\r\n\r\n    image = Image.open(image_path)\r\n\r\n    for new_size in [(256, 256), (128, 128), (64, 64), (32, 32), (16, 16)]:\r\n        current_size_dir = new_size[0]\r\n        new_pickeled_image_path = '{}{}\\\\{}'.format(PICKELED_IMAGES_DIR, current_size_dir, image_id)\r\n        r_image = image.resize(new_size)\r\n        r_image_np = np.array(r_image)\r\n\r\n        with open(new_pickeled_image_path, 'wb') as pickled_image:\r\n            pickle.dump(r_image_np, pickled_image)\r\n\r\ndef read_batch_images_to_pickle(batch_number):\r\n    batch_path = '{}{}{}'.format(BATCHES_DIR, BATCHES_FILES_ROOT, batch_number)\r\n    batch = pd.read_csv(batch_path)\r\n\r\n    images_ids = batch['image_id'].to_list()\r\n\r\n    nb_images = 1\r\n    total_images = len(images_ids)\r\n    for image in images_ids:\r\n        print(\"=====> image {} / {}\".format(nb_images, total_images))\r\n        read_image_to_pickle(image)\r\n        nb_images += 1\r\n\r\n\r\ndef read_batch_content(batch_number):\r\n    batch_path = '{}{}{}'.format(BATCHES_DIR, BATCHES_FILES_ROOT, batch_number)\r\n    batch = pd.read_csv(batch_path)\r\n\r\n    images_ids = batch['image_id'].to_list()\r\n    images_labels = batch['category_id'].to_list()\r\n\r\n    return images_ids, images_labels\r\n\r\n\r\ndef unpickle_image(image_size, image_id):\r\n    image_path = '{}{}\\\\{}'.format(PICKELED_IMAGES_DIR, image_size, image_id)\r\n    with open(image_path, 'rb') as f:\r\n        image = pickle.load(f)\r\n    return image\r\n\r\ndef split_images_to_train_and_test(images, labels):\r\n    print('> Started batch to train and test data')\r\n    nb_test_samples = int(0.2 * len(images)) + 1\r\n    starting_pos = random.randint(0, len(images) - nb_test_samples)\r\n\r\n    test_images = images[starting_pos:(starting_pos + nb_test_samples)]\r\n    test_labels = labels[starting_pos:(starting_pos + nb_test_samples)]\r\n\r\n    train_labels = np.concatenate((labels[:starting_pos], labels[(starting_pos + nb_test_samples):]))\r\n    train_images = np.concatenate((images[:starting_pos], images[(starting_pos + nb_test_samples):]))\r\n\r\n    return train_images, train_labels, test_images, test_labels\r\n\r\n\r\n\r\ndef split_to_batches(images_list, labels_list, nb_batches):\r\n    batch_nb_elements = int(len(images_list) / nb_batches) + 1\r\n    images_batches = []\r\n    labels_batches = []\r\n    for i in range(nb_batches):\r\n        images_batches.append(images_list[(i*batch_nb_elements):((i+1)*batch_nb_elements)])\r\n        labels_batches.append(labels_list[(i * batch_nb_elements):((i + 1) * batch_nb_elements)])\r\n    return images_batches, labels_batches\r\n\r\n\r\ndef load_batch(image_size, batch_images_list, batch_labels_list):\r\n\r\n    batch_images_loaded = []\r\n    nb_loaded = 0\r\n    for image in batch_images_list:\r\n        nb_loaded += 1\r\n        print(\"=====> Loading image :\", nb_loaded)\r\n        batch_images_loaded.append(unpickle_image(image_size, image))\r\n\r\n    batch_labels = np.array([[int(label_str)] for label_str in batch_labels_list])\r\n    batch_images = np.array(batch_images_loaded)\r\n\r\n    return batch_images, batch_labels\r\n\r\ndef reshape_images(pickeled_images_dataset_path, batch_path):\r\n    batch = pd.read_csv(batch_path)\r\n\r\n    images_ids = batch['image_id'].to_list()\r\n\r\n    nb = 1\r\n    for id in images_ids:\r\n        print(nb)\r\n        if nb > 29012:\r\n            for s in [256, 128, 64, 32, 16]:\r\n                with open('{}{}\\\\{}'.format(pickeled_images_dataset_path, s, id), 'rb') as o:\r\n                    old = pickle.load(o)\r\n\r\n                newim = old.reshape((s, s, 3))\r\n\r\n                with open('{}{}\\\\{}'.format(pickeled_images_dataset_path, s, id), 'wb') as n:\r\n                    pickle.dump(newim, n)\r\n        nb += 1\r\n\r\ndef pickle_batch(batch_number, images_size, nb_train_batches, nb_test_batches):\r\n    print(\r\n        \"********************************** Started Pickeling Batch {} - Image size is {} **********************************\".format(batch_number, images_size))\r\n\r\n    batch_images_ids_list, batchs_images_labels_list = read_batch_content(batch_number)\r\n\r\n    train_images_ids_list, train_images_labels_list, test_images_ids_list, test_images_labels_list = split_images_to_train_and_test(batch_images_ids_list, batchs_images_labels_list)\r\n\r\n\r\n    train_images_ids_batches, train_images_labels_batches = split_to_batches(train_images_ids_list, train_images_labels_list, nb_train_batches)\r\n    test_images_ids_batches, test_images_labels_batches = split_to_batches(test_images_ids_list,\r\n                                                                           test_images_labels_list, nb_test_batches)\r\n\r\n    if not os.path.exists(PICKELED_BACTHES_DIR + str(images_size)):\r\n        os.makedirs(PICKELED_BACTHES_DIR + str(images_size))\r\n\r\n\r\n    for i in range(nb_train_batches):\r\n        print(\"------------------------------------ Pickeling Train Batch {} on {} ------------------------------------\".format(\r\n            i + 1, nb_train_batches))\r\n\r\n        cur_batch_ids_list = train_images_ids_batches[i]\r\n        cur_batch_labels_list = train_images_labels_batches[i]\r\n\r\n        xtrain, ytrain = load_batch(images_size, cur_batch_ids_list, cur_batch_labels_list)\r\n\r\n        cur_batch_images_path = \"{}{}\\\\batch_{}_{}_train_images_{}\".format(PICKELED_BACTHES_DIR, images_size, batch_number, images_size, i)\r\n        cur_batch_labels_path = \"{}{}\\\\batch_{}_{}_train_labels_{}\".format(PICKELED_BACTHES_DIR, images_size, batch_number, images_size, i)\r\n        with open(cur_batch_images_path, 'wb') as pickeled_batch_images:\r\n            pickle.dump(xtrain, pickeled_batch_images)\r\n\r\n        with open(cur_batch_labels_path, 'wb') as pickeled_batch_labels:\r\n            pickle.dump(ytrain, pickeled_batch_labels)\r\n\r\n\r\n    for i in range(nb_test_batches):\r\n        print(\"------------------------------------ Pickeling Test Batch {} on {} ------------------------------------\".format(\r\n            i + 1, nb_test_batches))\r\n\r\n        cur_batch_ids_list = test_images_ids_batches[i]\r\n        cur_batch_labels_list = test_images_labels_batches[i]\r\n\r\n        xtest, ytest = load_batch(images_size, cur_batch_ids_list, cur_batch_labels_list)\r\n\r\n        cur_batch_images_path = \"{}{}\\\\batch_{}_{}_test_images_{}\".format(PICKELED_BACTHES_DIR, images_size, batch_number, images_size, i)\r\n        cur_batch_labels_path = \"{}{}\\\\batch_{}_{}_test_labels_{}\".format(PICKELED_BACTHES_DIR, images_size, batch_number, images_size, i)\r\n\r\n        with open(cur_batch_images_path, 'wb') as pickeled_batch_images:\r\n            pickle.dump(xtest, pickeled_batch_images)\r\n\r\n        with open(cur_batch_labels_path, 'wb') as pickeled_batch_labels:\r\n            pickle.dump(ytest, pickeled_batch_labels)\r\n\r\ndef load_pickeled_batch(batch_type, dataset_part, batch_number, images_size):\r\n    batch_images_path = '{}{}\\\\batch_{}_{}_{}_images_{}'.format(PICKELED_BACTHES_DIR, images_size, dataset_part, images_size, batch_type, batch_number)\r\n    batch_labels_path = '{}{}\\\\batch_{}_{}_{}_labels_{}'.format(PICKELED_BACTHES_DIR, images_size, dataset_part, images_size, batch_type, batch_number)\r\n\r\n    with open(batch_images_path, 'rb') as i:\r\n        batch_images = pickle.load(i)\r\n\r\n    with open(batch_labels_path, 'rb') as l:\r\n        batch_labels = pickle.load(l)\r\n\r\n    return batch_images, batch_labels
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- DatasetReader/DatasetReader_merzouk.py	(revision 38b6e0ec3c8bebf110b266a0953687c47ac27ac0)
+++ DatasetReader/DatasetReader_merzouk.py	(date 1588675813380)
@@ -161,7 +161,7 @@
     nb_loaded = 0
     for image in batch_images_list:
         nb_loaded += 1
-        print("=====> Loading image :", nb_loaded)
+        print("=====> Loading image :", nb_loaded,image)
         batch_images_loaded.append(unpickle_image(image_size, image))
 
     batch_labels = np.array([[int(label_str)] for label_str in batch_labels_list])
@@ -176,7 +176,7 @@
 
     nb = 1
     for id in images_ids:
-        print(nb)
+        print(nb,id)
         if nb > 29012:
             for s in [256, 128, 64, 32, 16]:
                 with open('{}{}\\{}'.format(pickeled_images_dataset_path, s, id), 'rb') as o:
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"JavaScriptSettings\">\r\n    <option name=\"languageLevel\" value=\"ES6\" />\r\n  </component>\r\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.7 (ml_tfcpu)\" project-jdk-type=\"Python SDK\" />\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- .idea/misc.xml	(revision 38b6e0ec3c8bebf110b266a0953687c47ac27ac0)
+++ .idea/misc.xml	(date 1588675346225)
@@ -3,5 +3,5 @@
   <component name="JavaScriptSettings">
     <option name="languageLevel" value="ES6" />
   </component>
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7 (ml_tfcpu)" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7 (tensorflow2gpu)" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
Index: .idea/KaggleCompetition2020.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<module type=\"PYTHON_MODULE\" version=\"4\">\r\n  <component name=\"NewModuleRootManager\">\r\n    <content url=\"file://$MODULE_DIR$\" />\r\n    <orderEntry type=\"jdk\" jdkName=\"Python 3.7 (ml_tfcpu)\" jdkType=\"Python SDK\" />\r\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\r\n  </component>\r\n  <component name=\"TestRunnerService\">\r\n    <option name=\"PROJECT_TEST_RUNNER\" value=\"pytest\" />\r\n  </component>\r\n</module>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- .idea/KaggleCompetition2020.iml	(revision 38b6e0ec3c8bebf110b266a0953687c47ac27ac0)
+++ .idea/KaggleCompetition2020.iml	(date 1588675346182)
@@ -2,7 +2,7 @@
 <module type="PYTHON_MODULE" version="4">
   <component name="NewModuleRootManager">
     <content url="file://$MODULE_DIR$" />
-    <orderEntry type="jdk" jdkName="Python 3.7 (ml_tfcpu)" jdkType="Python SDK" />
+    <orderEntry type="jdk" jdkName="Python 3.7 (tensorflow2gpu)" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="TestRunnerService">
